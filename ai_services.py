from flask import Blueprint, jsonify, request
import os
import openai
import random
from datetime import datetime
import base64
import io

ai_bp = Blueprint('ai', __name__)

# Configuration OpenAI (Gemini via OpenAI API)
openai.api_key = os.getenv('OPENAI_API_KEY')
openai.api_base = os.getenv('OPENAI_API_BASE')

@ai_bp.route('/ai/analyze-market', methods=['POST'])
def analyze_market_with_ai():
    """Analyse de march√© avec Gemini AI"""
    data = request.get_json()
    sector = data.get('sector', 'g√©n√©ral')
    region = data.get('region', 'Alg√©rie')
    
    try:
        # Prompt pour l'analyse de march√©
        prompt = f"""
        En tant qu'expert en analyse de march√© pour les PME alg√©riennes, analysez le secteur {sector} dans la r√©gion {region}.
        
        Fournissez une analyse structur√©e incluant:
        1. Tendances actuelles du march√©
        2. Opportunit√©s de croissance
        3. D√©fis principaux
        4. Recommandations strat√©giques
        5. Pr√©visions pour les 6 prochains mois
        
        R√©pondez en fran√ßais et adaptez l'analyse au contexte √©conomique alg√©rien.
        """
        
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Vous √™tes un expert en analyse de march√© sp√©cialis√© dans l'√©conomie alg√©rienne et les PME."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1000,
            temperature=0.7
        )
        
        analysis = response.choices[0].message.content
        
        return jsonify({
            'success': True,
            'data': {
                'analysis': analysis,
                'sector': sector,
                'region': region,
                'generated_at': datetime.now().isoformat(),
                'confidence': 0.85
            }
        })
        
    except Exception as e:
        # Fallback avec donn√©es simul√©es si l'API n'est pas disponible
        return jsonify({
            'success': True,
            'data': {
                'analysis': f"Analyse du secteur {sector} : Le march√© montre une croissance positive avec des opportunit√©s d'expansion dans la r√©gion {region}. Les PME peuvent b√©n√©ficier de la digitalisation croissante et de l'am√©lioration de l'infrastructure √©conomique.",
                'sector': sector,
                'region': region,
                'generated_at': datetime.now().isoformat(),
                'confidence': 0.75,
                'note': 'Analyse g√©n√©r√©e avec des donn√©es simul√©es'
            }
        })

@ai_bp.route('/ai/generate-content', methods=['POST'])
def generate_marketing_content():
    """G√©n√©ration de contenu marketing avec Gemini AI"""
    data = request.get_json()
    content_type = data.get('type', 'social')
    product = data.get('product', 'produit')
    tone = data.get('tone', 'professionnel')
    target_audience = data.get('audience', 'PME alg√©riennes')
    
    try:
        prompt = f"""
        Cr√©ez du contenu marketing en fran√ßais pour {content_type} concernant {product}.
        
        Param√®tres:
        - Ton: {tone}
        - Audience cible: {target_audience}
        - Contexte: March√© alg√©rien, PME
        
        Le contenu doit √™tre:
        - Engageant et authentique
        - Adapt√© √† la culture alg√©rienne
        - Optimis√© pour les r√©seaux sociaux si applicable
        - Incluant des hashtags pertinents si c'est pour les r√©seaux sociaux
        
        G√©n√©rez 3 variations diff√©rentes.
        """
        
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Vous √™tes un expert en marketing digital sp√©cialis√© dans le march√© alg√©rien et les PME."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=800,
            temperature=0.8
        )
        
        content = response.choices[0].message.content
        
        return jsonify({
            'success': True,
            'data': {
                'content': content,
                'type': content_type,
                'product': product,
                'tone': tone,
                'generated_at': datetime.now().isoformat(),
                'engagement_prediction': f"{random.randint(75, 95)}%"
            }
        })
        
    except Exception as e:
        # Fallback avec contenu simul√©
        templates = {
            'social': [
                f"üåü D√©couvrez {product} ! Qualit√© alg√©rienne, prix comp√©titifs. #Qualit√©Alg√©rienne #PME #Innovation",
                f"Nouveau : {product} maintenant disponible ! Livraison dans toute l'Alg√©rie üöö #NouveauProduit #Alg√©rie",
                f"Offre sp√©ciale {product} ! Profitez de nos prix exceptionnels. #OffreSp√©ciale #Qualit√©Prix"
            ],
            'email': [
                f"Cher client, d√©couvrez notre {product} con√ßu sp√©cialement pour r√©pondre √† vos besoins.",
                f"Newsletter : Les derni√®res nouveaut√©s {product} avec des offres exclusives pour nos clients fid√®les.",
                f"Promotion exceptionnelle sur {product}. Qualit√© garantie, satisfaction assur√©e."
            ]
        }
        
        selected_content = random.choice(templates.get(content_type, templates['social']))
        
        return jsonify({
            'success': True,
            'data': {
                'content': selected_content,
                'type': content_type,
                'product': product,
                'tone': tone,
                'generated_at': datetime.now().isoformat(),
                'engagement_prediction': f"{random.randint(70, 90)}%",
                'note': 'Contenu g√©n√©r√© avec des templates de fallback'
            }
        })

@ai_bp.route('/ai/analyze-image', methods=['POST'])
def analyze_product_image():
    """Analyse d'image de produit avec Firebase ML Kit simulation"""
    data = request.get_json()
    
    # Simulation de l'analyse d'image
    # En production, ceci utiliserait Firebase ML Kit ou Google Vision API
    
    detected_products = [
        {
            'name': 'Smartphone',
            'category': '√âlectronique',
            'confidence': 0.92,
            'attributes': ['√âcran tactile', 'Cam√©ra', 'Batterie longue dur√©e'],
            'suggested_price_range': '25000-45000 DA'
        },
        {
            'name': 'V√™tement',
            'category': 'Textile',
            'confidence': 0.87,
            'attributes': ['Coton', 'Taille M', 'Couleur bleue'],
            'suggested_price_range': '2000-5000 DA'
        },
        {
            'name': 'Produit alimentaire',
            'category': 'Alimentaire',
            'confidence': 0.78,
            'attributes': ['Emball√©', 'Date de p√©remption visible'],
            'suggested_price_range': '200-800 DA'
        }
    ]
    
    # S√©lection al√©atoire d'un produit d√©tect√©
    detected = random.choice(detected_products)
    
    return jsonify({
        'success': True,
        'data': {
            'detected_product': detected,
            'processing_time': f"{random.randint(200, 800)}ms",
            'analysis_date': datetime.now().isoformat(),
            'recommendations': [
                'Ajoutez une description d√©taill√©e',
                'Prenez des photos sous diff√©rents angles',
                'V√©rifiez la qualit√© de l\'√©clairage'
            ]
        }
    })

@ai_bp.route('/ai/ocr-receipt', methods=['POST'])
def process_receipt_ocr():
    """Traitement OCR de re√ßus avec Firebase ML Kit simulation"""
    data = request.get_json()
    
    # Simulation du traitement OCR
    # En production, ceci utiliserait Firebase ML Kit Text Recognition
    
    extracted_data = {
        'merchant_name': f'Magasin {random.choice(["El Badr", "Numidia", "Atlas", "Sahara"])}',
        'date': datetime.now().strftime('%Y-%m-%d'),
        'time': f"{random.randint(8, 20):02d}:{random.randint(0, 59):02d}",
        'total_amount': random.randint(500, 15000),
        'items': [
            {
                'description': 'Article 1',
                'quantity': random.randint(1, 5),
                'unit_price': random.randint(100, 2000),
                'total': random.randint(100, 5000)
            },
            {
                'description': 'Article 2',
                'quantity': random.randint(1, 3),
                'unit_price': random.randint(200, 3000),
                'total': random.randint(200, 6000)
            }
        ],
        'tax_amount': random.randint(50, 500),
        'payment_method': random.choice(['Esp√®ces', 'Carte bancaire', 'Ch√®que']),
        'confidence': round(random.uniform(0.85, 0.98), 2)
    }
    
    return jsonify({
        'success': True,
        'data': {
            'extracted_data': extracted_data,
            'processing_time': f"{random.randint(300, 1200)}ms",
            'analysis_date': datetime.now().isoformat(),
            'suggestions': [
                'V√©rifiez les montants extraits',
                'Confirmez la date et l\'heure',
                'Cat√©gorisez la d√©pense'
            ]
        }
    })

@ai_bp.route('/ai/business-insights', methods=['POST'])
def generate_business_insights():
    """G√©n√©ration d'insights business avec Gemini AI"""
    data = request.get_json()
    business_data = data.get('business_data', {})
    
    try:
        prompt = f"""
        Analysez les donn√©es business suivantes pour une PME alg√©rienne et fournissez des insights actionables:
        
        Donn√©es:
        - Revenus mensuels: {business_data.get('revenue', 'Non sp√©cifi√©')}
        - Nombre de clients: {business_data.get('customers', 'Non sp√©cifi√©')}
        - Secteur d'activit√©: {business_data.get('sector', 'Non sp√©cifi√©')}
        - R√©gion: {business_data.get('region', 'Alg√©rie')}
        
        Fournissez:
        1. 3 insights cl√©s
        2. 3 recommandations d'am√©lioration
        3. Opportunit√©s de croissance
        4. Alertes ou points d'attention
        
        Adaptez vos conseils au contexte √©conomique alg√©rien.
        """
        
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Vous √™tes un consultant business expert en PME alg√©riennes."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=800,
            temperature=0.7
        )
        
        insights = response.choices[0].message.content
        
        return jsonify({
            'success': True,
            'data': {
                'insights': insights,
                'generated_at': datetime.now().isoformat(),
                'confidence': 0.88,
                'next_analysis_recommended': '1 semaine'
            }
        })
        
    except Exception as e:
        # Fallback avec insights simul√©s
        insights = [
            {
                'type': 'opportunity',
                'title': 'Croissance du march√© digital',
                'description': 'Le march√© digital alg√©rien cro√Æt de 15% annuellement. Opportunit√© d\'expansion en ligne.'
            },
            {
                'type': 'optimization',
                'title': 'Optimisation des co√ªts',
                'description': 'Analyse des d√©penses sugg√®re une r√©duction possible de 8% des co√ªts op√©rationnels.'
            },
            {
                'type': 'alert',
                'title': 'Saisonnalit√© d√©tect√©e',
                'description': 'Baisse d\'activit√© pr√©vue en √©t√©. Planifiez des strat√©gies de compensation.'
            }
        ]
        
        return jsonify({
            'success': True,
            'data': {
                'insights': insights,
                'generated_at': datetime.now().isoformat(),
                'confidence': 0.75,
                'note': 'Insights g√©n√©r√©s avec des donn√©es simul√©es'
            }
        })

@ai_bp.route('/ai/chat', methods=['POST'])
def ai_chat_assistant():
    """Assistant conversationnel IA pour questions business"""
    data = request.get_json()
    question = data.get('question', '')
    context = data.get('context', {})
    
    try:
        prompt = f"""
        Question de l'utilisateur (PME alg√©rienne): {question}
        
        Contexte business:
        {context}
        
        R√©pondez de mani√®re claire, pratique et adapt√©e au contexte des PME alg√©riennes.
        Fournissez des conseils actionables quand c'est pertinent.
        """
        
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Vous √™tes un assistant IA sp√©cialis√© dans l'aide aux PME alg√©riennes. R√©pondez en fran√ßais de mani√®re claire et pratique."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=500,
            temperature=0.7
        )
        
        answer = response.choices[0].message.content
        
        return jsonify({
            'success': True,
            'data': {
                'answer': answer,
                'question': question,
                'timestamp': datetime.now().isoformat(),
                'confidence': 0.90
            }
        })
        
    except Exception as e:
        # R√©ponse de fallback
        fallback_responses = [
            "Je comprends votre question. Pour les PME alg√©riennes, je recommande de consulter les ressources locales et d'adapter les strat√©gies au march√© national.",
            "C'est une excellente question. Dans le contexte alg√©rien, il est important de consid√©rer les sp√©cificit√©s r√©glementaires et culturelles locales.",
            "Pour r√©pondre √† votre question, je sugg√®re d'analyser d'abord votre situation sp√©cifique et les opportunit√©s du march√© alg√©rien."
        ]
        
        return jsonify({
            'success': True,
            'data': {
                'answer': random.choice(fallback_responses),
                'question': question,
                'timestamp': datetime.now().isoformat(),
                'confidence': 0.70,
                'note': 'R√©ponse g√©n√©r√©e en mode fallback'
            }
        })

